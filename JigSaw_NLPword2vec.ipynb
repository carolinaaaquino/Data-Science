{"cells":[{"cell_type":"markdown","source":["#NLP with model word2vec \n\nUse of the dataset Jigsaw to implement a NLP model, word2vec, with Spark and NLTK.\n\nData set in: https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge/"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f738c72a-ae5e-4aec-a9cc-95ce0873f00c","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["spark"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"70aee1e7-5881-4a3c-a657-5712eb64ac25","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=3200366722064946#setting/sparkui/0308-213932-ow5u6zhd/driver-4251108239568602438\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.3.0</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["\n","            <div>\n","                <p><b>SparkSession - hive</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"/?o=3200366722064946#setting/sparkui/0308-213932-ow5u6zhd/driver-4251108239568602438\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.3.0</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[8]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>Databricks Shell</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]}}],"execution_count":0},{"cell_type":"code","source":["%pip install --upgrade pip"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3997002d-eef7-4a36-bcae-67cc40556a8c","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Python interpreter will be restarted.\nRequirement already satisfied: pip in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d033e31f-d1ae-4128-967d-3b2147b562fd/lib/python3.9/site-packages (21.2.4)\nCollecting pip\n  Downloading pip-23.0.1-py3-none-any.whl (2.1 MB)\nInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 21.2.4\n    Uninstalling pip-21.2.4:\n      Successfully uninstalled pip-21.2.4\nSuccessfully installed pip-23.0.1\nPython interpreter will be restarted.\n"]}],"execution_count":0},{"cell_type":"code","source":["%pip install nltk"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7a78ad0c-8703-436e-9b90-3c0108a74b96","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Python interpreter will be restarted.\nCollecting nltk\n  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.5/1.5 MB 7.7 MB/s eta 0:00:00\nCollecting tqdm\n  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 77.1/77.1 kB 6.3 MB/s eta 0:00:00\nRequirement already satisfied: click in /databricks/python3/lib/python3.9/site-packages (from nltk) (8.0.3)\nCollecting regex>=2021.8.3\n  Downloading regex-2022.10.31-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (769 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 770.0/770.0 kB 55.6 MB/s eta 0:00:00\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.9/site-packages (from nltk) (1.0.1)\nInstalling collected packages: tqdm, regex, nltk\nSuccessfully installed nltk-3.8.1 regex-2022.10.31 tqdm-4.65.0\nPython interpreter will be restarted.\n"]}],"execution_count":0},{"cell_type":"markdown","source":["Import and read of Dataset Jigsaw."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"331a8d4a-90c4-482d-8989-21d5ff732669","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["path = \"/FileStore/tables/train.csv\""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"68db08f1-729d-4fe0-955a-1f5c71956881","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["jigsaw_df = spark.read.option(\"header\", True).option(\"multiline\", True).option(\"escape\", \"\\\"\").csv(path)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"20401451-ae32-422a-a334-671e6b0a64e5","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["An Pipeline maded with \"Tokenizer\", \"Stop Words Remover\", \"Numbers Remover\" and \"Stemmer\"."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"fcdcbfe6-6589-4ccc-9243-db19955d283f","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from nltk.stem.snowball import EnglishStemmer\nfrom pyspark.ml import Pipeline, Transformer\nfrom pyspark.ml.feature import RegexTokenizer, StopWordsRemover\nfrom pyspark.sql.functions import col, explode, split, udf\nfrom pyspark.sql.types import ArrayType, StringType, DoubleType\n\nclass Stemmer(Transformer):\n    def __init__(self, inputCol, outputCol=None):\n        super(Stemmer, self).__init__()\n        self.input_column = inputCol\n        self.output_column = outputCol or inputCol\n\n    def _transform(self, df):\n        function = (lambda x: [EnglishStemmer().stem(y) for y in x if len(y) > 1])\n        stemmer_udf = udf(function, ArrayType(StringType()))\n        return df.withColumn(self.output_column, stemmer_udf(self.input_column))\n    \nclass NumbersRemover(Transformer):\n    def __init__(self, inputCol, outputCol=None):\n        super(NumbersRemover, self).__init__()\n        self.input_column = inputCol\n        self.output_column = outputCol or inputCol\n\n    def _transform(self, df):\n        numbers_remover = udf(lambda x: [y for y in x if not y.isdigit()], ArrayType(StringType()))\n        return df.withColumn(self.output_column, numbers_remover(self.input_column))\n                             \ntokenizer = RegexTokenizer(inputCol=\"comment_text\",\n                           outputCol=\"comment_text_tokens\",\n                           pattern=r\"\\W\",\n                           toLowercase=True)\n\nsw_remover = StopWordsRemover(inputCol=\"comment_text_tokens\",\n                              outputCol=\"comment_text_sw_removed\")\n\nnumbers_remover = NumbersRemover(inputCol=\"comment_text_sw_removed\",\n                                 outputCol=\"comment_text_num_removed\")\n\nstemmer = Stemmer(inputCol=\"comment_text_num_removed\", \n                  outputCol=\"comment_text_stem\")\n\n\nnlp_pipeline = Pipeline(stages=[tokenizer, sw_remover, numbers_remover, stemmer])\n\nprocessed_df = nlp_pipeline.fit(jigsaw_df).transform(jigsaw_df)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4f628a8c-2b54-4831-a3fb-c442f8c6e26a","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["processed_df_path = \"/dbfs/FileStore/jigsaw_processed\"\nprocessed_df.write.parquet(processed_df_path, mode=\"overwrite\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5c280105-77dc-4acf-acc5-7ebc01466da4","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Model word2vec trained with the processed dataframe."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0f7a76bf-0298-4a80-871e-5959389ac854","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["jigsaw_processed = spark.read.parquet(processed_df_path)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d30fa4c6-9def-420d-8b60-8081ea812b57","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from pyspark.ml.feature import Word2Vec\n\nvector_size = 50\nwindow_size = 10\nmax_iter = 1\nnum_partitions = 1\n\nparameters = {\n    \"vectorSize\": vector_size,\n    \"windowSize\": window_size,\n    \"maxIter\": max_iter,\n    \"numPartitions\": num_partitions,\n}\n\nw2v_model = Word2Vec(inputCol=\"comment_text_stem\", outputCol=\"features\", minCount=3, **parameters)\n\nmodel = w2v_model.fit(jigsaw_processed)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"261ec100-b993-4e78-b12f-62db7fec1507","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# model save\nmodel.write().overwrite().save(\"/dbfs/FileStore/models/word2vec/\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7d2edb98-08fe-4e54-9a1d-df82b98c3e7c","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# model load\nfrom pyspark.ml.feature import Word2VecModel\n\nmodel = Word2VecModel.load(\"/dbfs/FileStore/models/word2vec/\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d305b2e1-1ef9-4872-b587-d260004d2239","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Embeddings calculated with a dataframe from the words of dataset Jigsaw."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"934171e2-60a3-426f-8ffe-afd54e76efb9","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# words dataframe: \nfrom pyspark.sql.functions import col, explode, split\n\nwords = jigsaw_processed.withColumnRenamed(\"comment_text_num_removed\", \"words\").withColumn(\"words\", explode(\"words\")).select(\"words\").distinct().withColumn(\"words_array\", split(col(\"words\"), \",\"))\n\noutput_col_name = \"comment_text_stem\"\nwords = Stemmer(inputCol=\"words_array\", outputCol=output_col_name).transform(words)\n\nembeddings = model.transform(words)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"de3d3308-7dfb-417e-a57e-89e3d1fc75b1","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql import Window\nfrom pyspark.sql.functions import row_number\nfrom pyspark.sql.types import ArrayType, DoubleType\n\nto_array = udf(lambda v: v.toArray().tolist(), ArrayType(DoubleType()))\n\nembeddings = embeddings.withColumn(\"features\", to_array(\"features\"))\nembeddings = embeddings.withColumn(\"word_index\", row_number().over(Window.orderBy(\"words\")))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d90df249-f783-450e-98db-e4bb9b4d2531","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# dataframe\nembeddings.write.parquet(f\"/dbfs/FileStore/embeddings_{vector_size}_{window_size}_{max_iter}_{num_partitions}\", mode=\"overwrite\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"039790ef-c82b-4444-8f43-8f4aeea5cded","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Proximity text with the word `finland`."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0b4d8af2-5908-43cb-beac-c4345b969e67","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["token1 = \"finland\"\ndisplay(model.findSynonyms(token1, 10))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e02016a8-6787-41f7-a4f3-aa582241777c","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["abkhazia",0.8467004895210266],["frontier",0.8410831689834595],["austria",0.8396831154823303],["imperi",0.8379868268966675],["austrian",0.8323290348052979],["kaliningrad",0.8281496167182922],["romania",0.8276630640029907],["bagramyan",0.8269601464271545],["tabsmiljan",0.8252956867218018],["andorra",0.8251665830612183]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"word","type":"\"string\"","metadata":"{}"},{"name":"similarity","type":"\"double\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n","  .table-result-container {\n","    max-height: 300px;\n","    overflow: auto;\n","  }\n","  table, th, td {\n","    border: 1px solid black;\n","    border-collapse: collapse;\n","  }\n","  th, td {\n","    padding: 5px;\n","  }\n","  th {\n","    text-align: left;\n","  }\n","</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>word</th><th>similarity</th></tr></thead><tbody><tr><td>abkhazia</td><td>0.8467004895210266</td></tr><tr><td>frontier</td><td>0.8410831689834595</td></tr><tr><td>austria</td><td>0.8396831154823303</td></tr><tr><td>imperi</td><td>0.8379868268966675</td></tr><tr><td>austrian</td><td>0.8323290348052979</td></tr><tr><td>kaliningrad</td><td>0.8281496167182922</td></tr><tr><td>romania</td><td>0.8276630640029907</td></tr><tr><td>bagramyan</td><td>0.8269601464271545</td></tr><tr><td>tabsmiljan</td><td>0.8252956867218018</td></tr><tr><td>andorra</td><td>0.8251665830612183</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Parameters test with two different models word2vec. Test results with the words ``finland`` and ``danmark``, cosine similarity."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ce7ef6f6-abcc-4f5c-9149-65567f6c9c6f","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["#model 1\n\nvector_size = 100\nwindow_size = 7\nmax_iter = 1\nnum_partitions = 1\n\nparameters = {\n    \"vectorSize\": vector_size,\n    \"windowSize\": window_size,\n    \"maxIter\": max_iter,\n    \"numPartitions\": num_partitions,\n}\n\nw2v_model = Word2Vec(inputCol=\"comment_text_stem\", outputCol=\"features\", minCount=3, **parameters)\n\nmodel_1 = w2v_model.fit(jigsaw_processed)\n\nmodel_1.write().overwrite().save(\"/dbfs/FileStore/models/word2vec/\")\nmodel_1 = Word2VecModel.load(\"/dbfs/FileStore/models/word2vec/\")\n\nembeddings_1 = model_1.transform(words)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"719be454-5319-498b-9121-89599eeee7f8","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# model 2\n\nvector_size = 50\nwindow_size = 12\nmax_iter = 1\nnum_partitions = 1\n\nparameters = {\n    \"vectorSize\": vector_size,\n    \"windowSize\": window_size,\n    \"maxIter\": max_iter,\n    \"numPartitions\": num_partitions,\n}\n\nw2v_model = Word2Vec(inputCol=\"comment_text_stem\", outputCol=\"features\", minCount=3, **parameters)\n\nmodel_2 = w2v_model.fit(jigsaw_processed)\n\nmodel_2.write().overwrite().save(\"/dbfs/FileStore/models/word2vec/\")\nmodel_2 = Word2VecModel.load(\"/dbfs/FileStore/models/word2vec/\")\n\nembeddings_2 = model_2.transform(words)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a9bc28cc-1efa-4649-9cfa-6568781f1657","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["import numpy as np\n\ndef cosine_sim(a, b):\n    def l2_norm(v):\n        return np.sqrt(np.sum(np.array(a)**2))\n    cos_sim = np.dot(a, b)/(l2_norm(a)*l2_norm(b))\n    return cos_sim"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"808f85d6-c11a-480f-8429-9522b0dc6122","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#result - model 1\nword1 = \"finland\"\nword2 = \"danmark\"\n\nword1_embedding1 = embeddings_1.filter(col(\"words\") == word1).select(\"features\").collect()[0][0]\nword2_embedding1 = embeddings_1.filter(col(\"words\") == word2).select(\"features\").collect()[0][0]\n\ncosine_sim(word1_embedding1,word2_embedding1)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7d9a83bb-d7b7-45dd-9f0b-748eaff48c7a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Out[28]: 0.23997115561315505"]}],"execution_count":0},{"cell_type":"code","source":["#result - model 2\nword1_embedding2 = embeddings_2.filter(col(\"words\") == word1).select(\"features\").collect()[0][0]\nword2_embedding2 = embeddings_2.filter(col(\"words\") == word2).select(\"features\").collect()[0][0]\n\ncosine_sim(word1_embedding2, word2_embedding2)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ed2a3003-8cd0-4c35-bbc5-55d815748343","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Out[29]: 0.3335125051069983"]}],"execution_count":0},{"cell_type":"markdown","source":["The model 2 gave the best result."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f5ac71fb-28c6-466a-bcfa-4021bc72e89f","inputWidgets":{},"title":""}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"JigSaw_NLPword2vec","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
